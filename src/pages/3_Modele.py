import streamlit as st
import torch
from pathlib import Path
import sys
import json
import subprocess
import time

# Fix for "could not create a primitive" error in PyTorch 2.9.0+cpu
torch.backends.mkldnn.enabled = False

# Add project root to path for imports
project_root = Path(__file__).resolve().parents[2]
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

from src.services.yaml_loader import YamlLoader
from src.models.model_factory import ModelFactory

st.title("ğŸ§  ModÃ¨le de classification")

# Class names
CLASS_NAMES = [
    'basophil', 'eosinophil', 'erythroblast', 'immature_granulocyte',
    'lymphocyte', 'monocyte', 'neutrophil', 'platelet'
]

# Load configuration
@st.cache_resource
def load_config():
    try:
        yaml_loader = YamlLoader()
        return yaml_loader.config, yaml_loader
    except Exception as e:
        st.error(f"Erreur lors du chargement de la configuration: {e}")
        return None, None

config, yaml_loader = load_config()

if config is None:
    st.stop()

# Section 1: PrÃ©-traitement des images
st.header("ğŸ“Š 1. PrÃ©-traitement des images")

with st.expander("âš¡ DÃ©tails du prÃ©-traitement", expanded=True):
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Configuration d'entraÃ®nement")
        training_config = config.get('training', {})
        st.write(f"- **Taille d'image:** {training_config.get('img_size', 224)}x{training_config.get('img_size', 224)}")
        st.write(f"- **Batch size:** {training_config.get('batch_size', 32)}")
        st.write(f"- **Epochs:** {training_config.get('epochs', 20)}")
        st.write(f"- **Learning rate:** {training_config.get('learning_rate', 0.001)}")
    
    with col2:
        st.subheader("ğŸ”„ Augmentations")
        aug_config = config.get('augmentation', {}).get('train', {})
        if aug_config.get('horizontal_flip'):
            st.write("âœ… Flip horizontal")
        if aug_config.get('vertical_flip'):
            st.write("âœ… Flip vertical")
        rotation = aug_config.get('rotation_degrees', 0)
        if rotation > 0:
            st.write(f"âœ… Rotation: Â±{rotation}Â°")
        if aug_config.get('color_jitter'):
            st.write("âœ… Color jitter")
    
    st.subheader("ğŸ¯ Normalisation")
    norm_config = config.get('model', {}).get('normalization', {})
    st.write(f"- **Mean:** {norm_config.get('mean', [0.485, 0.456, 0.406])}")
    st.write(f"- **Std:** {norm_config.get('std', [0.229, 0.224, 0.225])}")

# Section 2: Architecture du modÃ¨le
st.header("ğŸ›ï¸ 2. Architecture du modÃ¨le")

model_config = config.get('model', {})
model_name = model_config.get('name', 'resnet18')
pretrained = model_config.get('pretrained', True)

st.markdown(f"""
### ModÃ¨le utilisÃ©: **{model_name.upper()}**

- **Type:** Transfer Learning (ResNet)
- **PrÃ©-entraÃ®nÃ©:** {'Oui' if pretrained else 'Non'}
- **Poids:** {model_config.get('pretrained_weights', 'IMAGENET1K_V1')}
- **Nombre de classes:** {len(CLASS_NAMES)}
""")

with st.expander("ğŸ” Voir les classes"):
    cols = st.columns(4)
    for i, class_name in enumerate(CLASS_NAMES):
        with cols[i % 4]:
            st.write(f"{i+1}. {class_name}")

# Load model info
@st.cache_resource
def get_model_info(_config, device_str: str):
    try:
        device = torch.device(device_str)
        model = ModelFactory.create_model(_config, len(CLASS_NAMES), device)
        
        # Count parameters
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        
        return {
            'total_params': total_params,
            'trainable_params': trainable_params,
            'device': str(device)
        }
    except Exception as e:
        return {'error': str(e)}

device = ModelFactory.get_device()
model_info = get_model_info(config, str(device))

if 'error' not in model_info:
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ParamÃ¨tres totaux", f"{model_info['total_params']:,}")
    with col2:
        st.metric("ParamÃ¨tres entraÃ®nables", f"{model_info['trainable_params']:,}")
    with col3:
        st.metric("Device", model_info['device'])

# Section 3: EntraÃ®nement
st.header("ğŸš€ 3. EntraÃ®nement")

st.markdown("""
- **Dataset:** Mendeley Blood Cell Images
- **Optimiseur:** Adam
- **Loss function:** CrossEntropyLoss avec pondÃ©ration des classes
- **Data split:** 70% train / 15% validation / 15% test
""")

# Section 4: RÃ©-entraÃ®nement du modÃ¨le
st.header("ğŸ”„ 4. RÃ©-entraÃ®nement du modÃ¨le")

st.markdown("""
Cliquez sur le bouton ci-dessous pour lancer l'entraÃ®nement d'un nouveau modÃ¨le.
Le modÃ¨le sera automatiquement sauvegardÃ© dans le rÃ©pertoire `checkpoints`.
""")

# Initialize session state for training status
if 'training_in_progress' not in st.session_state:
    st.session_state.training_in_progress = False

col1, col2 = st.columns([1, 3])

with col1:
    if st.button("ğŸš€ Lancer l'entraÃ®nement", type="primary", disabled=st.session_state.training_in_progress):
        st.session_state.training_in_progress = True
        st.rerun()

with col2:
    if st.session_state.training_in_progress:
        st.info("â³ EntraÃ®nement en cours... Veuillez patienter.")

# Training execution
if st.session_state.training_in_progress:
    with st.expander("ğŸ“Š DÃ©tails de l'entraÃ®nement", expanded=True):
        status_placeholder = st.empty()
        log_placeholder = st.empty()
        
        try:
            status_placeholder.info("ğŸ”„ DÃ©marrage de l'entraÃ®nement...")
            
            # Run training script using uv
            train_script = Path(yaml_loader.project_root) / "src" / "pipe" / "train_model.py"
            
            # Use subprocess to run the training
            process = subprocess.Popen(
                ["uv", "run", "python", "-m", "src.pipe.train_model"],
                cwd=yaml_loader.project_root,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True,
                bufsize=1
            )
            
            # Capture output in real-time
            output_lines = []
            for line in process.stdout:
                output_lines.append(line)
                log_placeholder.text_area("ğŸ“ Logs d'entraÃ®nement", 
                                         value="".join(output_lines[-50:]),  # Show last 50 lines
                                         height=300)
            
            # Wait for process to complete
            process.wait()
            
            if process.returncode == 0:
                status_placeholder.success("âœ… EntraÃ®nement terminÃ© avec succÃ¨s!")
                st.success(f"ğŸ‰ Le nouveau modÃ¨le a Ã©tÃ© sauvegardÃ© dans: `{config['paths']['models']['checkpoints']}`")
                st.info("ğŸ’¡ RafraÃ®chissez la page pour voir les nouvelles mÃ©triques.")
                
                # Reset training state
                time.sleep(2)
                st.session_state.training_in_progress = False
                st.rerun()
            else:
                status_placeholder.error(f"âŒ Erreur lors de l'entraÃ®nement (code: {process.returncode})")
                st.session_state.training_in_progress = False
                
        except Exception as e:
            status_placeholder.error(f"âŒ Erreur: {str(e)}")
            st.session_state.training_in_progress = False

st.markdown("---")

# Section 5: Ã‰valuation
st.header("ğŸ¯ 5. Ã‰valuation")

# Load metrics by default from checkpoints directory
@st.cache_data
def load_evaluation_metrics():
    """Load evaluation metrics from the checkpoints directory."""
    metrics_path = Path(yaml_loader.project_root) / "models" / "checkpoints" / "metrics.json"
    
    if metrics_path.exists():
        try:
            with open(metrics_path, 'r') as f:
                return json.load(f), None
        except Exception as e:
            return None, f"Erreur lors du chargement des mÃ©triques: {e}"
    else:
        return None, "Aucun fichier de mÃ©triques trouvÃ©"

# Check for saved model
checkpoint_path = Path(yaml_loader.project_root) / "models" / "checkpoints" / "best_model.pth"
model_exists = checkpoint_path.exists()

if model_exists:
    import os
    from datetime import datetime
    
    # Get model file info
    model_size = os.path.getsize(checkpoint_path) / (1024 * 1024)  # Size in MB
    model_mtime = datetime.fromtimestamp(os.path.getmtime(checkpoint_path))
    
    st.info(f"ğŸ“¦ ModÃ¨le trouvÃ©: `best_model.pth` ({model_size:.1f} MB) - DerniÃ¨re modification: {model_mtime.strftime('%Y-%m-%d %H:%M:%S')}")

# Load metrics automatically
metrics, error = load_evaluation_metrics()

if metrics is not None:
    st.success("âœ… MÃ©triques d'Ã©valuation chargÃ©es depuis le modÃ¨le entraÃ®nÃ©")
    
    # Display main metrics in prominent cards
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ğŸ¯ Test Accuracy", f"{metrics.get('accuracy', 0):.2%}")
    with col2:
        st.metric("ğŸ“ˆ Best Val Accuracy", f"{metrics.get('best_val_acc', 0):.2%}")
    with col3:
        st.metric("ğŸ‹ï¸ Final Train Accuracy", f"{metrics.get('final_train_acc', 0):.2%}")
    
    # Additional metrics details
    with st.expander("ğŸ“Š DÃ©tails complets des mÃ©triques", expanded=False):
        st.json(metrics)
        
        # Display training loss if available
        if 'final_train_loss' in metrics:
            st.write(f"**Final Training Loss:** {metrics['final_train_loss']:.4f}")
        
        # Display class names
        if 'class_names' in metrics:
            st.write("**Classes dÃ©tectÃ©es:**")
            cols = st.columns(4)
            for i, class_name in enumerate(metrics['class_names']):
                with cols[i % 4]:
                    st.write(f"â€¢ {class_name}")
elif model_exists:
    st.warning(f"âš ï¸ {error}")
    st.info("ğŸ’¡ Le modÃ¨le existe mais les mÃ©triques n'ont pas Ã©tÃ© sauvegardÃ©es. RÃ©-entraÃ®nez le modÃ¨le pour gÃ©nÃ©rer les mÃ©triques.")
else:
    st.warning(f"âš ï¸ {error}")
    st.info("ğŸ’¡ EntraÃ®nez d'abord le modÃ¨le en cliquant sur le bouton 'ğŸš€ Lancer l'entraÃ®nement' ci-dessus.")
    st.markdown("""
    **AprÃ¨s entraÃ®nement, cette section affichera:**
    - Accuracy sur le test set
    - Meilleure accuracy de validation
    - Accuracy finale d'entraÃ®nement
    - Loss finale d'entraÃ®nement
    """)

st.markdown("---")
st.caption("ğŸ› ï¸ Cette page utilise les services backend: ModelFactory, DataTransformService, YamlLoader")