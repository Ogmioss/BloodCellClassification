import streamlit as st
import torch
from pathlib import Path
import sys
import json
import subprocess
import time
import numpy as np
import pandas as pd
import plotly.figure_factory as ff
import plotly.graph_objects as go

# Fix for "could not create a primitive" error in PyTorch 2.9.0+cpu
torch.backends.mkldnn.enabled = False

# Add project root to path for imports
project_root = Path(__file__).resolve().parents[2]
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

from src.services.yaml_loader import YamlLoader
from src.models.model_factory import ModelFactory

st.title("üß† Mod√®le de classification")

# Class names
CLASS_NAMES = [
    'basophil', 'eosinophil', 'erythroblast', 'immature_granulocyte',
    'lymphocyte', 'monocyte', 'neutrophil', 'platelet'
]

# Load configuration
@st.cache_resource
def load_config():
    try:
        yaml_loader = YamlLoader()
        return yaml_loader.config, yaml_loader
    except Exception as e:
        st.error(f"Erreur lors du chargement de la configuration: {e}")
        return None, None

config, yaml_loader = load_config()

if config is None:
    st.stop()

# Section 1: Pr√©-traitement des images
st.header("üìä 1. Pr√©-traitement des images")

with st.expander("‚ö° D√©tails du pr√©-traitement", expanded=True):
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Configuration d'entra√Ænement")
        training_config = config.get('training', {})
        st.write(f"- **Taille d'image:** {training_config.get('img_size', 224)}x{training_config.get('img_size', 224)}")
        st.write(f"- **Batch size:** {training_config.get('batch_size', 32)}")
        st.write(f"- **Epochs:** {training_config.get('epochs', 20)}")
        st.write(f"- **Learning rate:** {training_config.get('learning_rate', 0.001)}")
    
    with col2:
        st.subheader("üîÑ Augmentations")
        aug_config = config.get('augmentation', {}).get('train', {})
        if aug_config.get('horizontal_flip'):
            st.write("‚úÖ Flip horizontal")
        if aug_config.get('vertical_flip'):
            st.write("‚úÖ Flip vertical")
        rotation = aug_config.get('rotation_degrees', 0)
        if rotation > 0:
            st.write(f"‚úÖ Rotation: ¬±{rotation}¬∞")
        if aug_config.get('color_jitter'):
            st.write("‚úÖ Color jitter")
    
    st.subheader("üéØ Normalisation")
    norm_config = config.get('model', {}).get('normalization', {})
    st.write(f"- **Mean:** {norm_config.get('mean', [0.485, 0.456, 0.406])}")
    st.write(f"- **Std:** {norm_config.get('std', [0.229, 0.224, 0.225])}")

# Section 2: Architecture du mod√®le
st.header("üèõÔ∏è 2. Architecture du mod√®le")

model_config = config.get('model', {})
model_name = model_config.get('name', 'resnet18')
pretrained = model_config.get('pretrained', True)

st.markdown(f"""
### Mod√®le utilis√©: **{model_name.upper()}**

- **Type:** Transfer Learning (ResNet)
- **Pr√©-entra√Æn√©:** {'Oui' if pretrained else 'Non'}
- **Poids:** {model_config.get('pretrained_weights', 'IMAGENET1K_V1')}
- **Nombre de classes:** {len(CLASS_NAMES)}
""")

with st.expander("üîç Voir les classes"):
    cols = st.columns(4)
    for i, class_name in enumerate(CLASS_NAMES):
        with cols[i % 4]:
            st.write(f"{i+1}. {class_name}")

# Load model info
@st.cache_resource
def get_model_info(_config, device_str: str):
    try:
        device = torch.device(device_str)
        model = ModelFactory.create_model(_config, len(CLASS_NAMES), device)
        
        # Count parameters
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        
        return {
            'total_params': total_params,
            'trainable_params': trainable_params,
            'device': str(device)
        }
    except Exception as e:
        return {'error': str(e)}

device = ModelFactory.get_device()
model_info = get_model_info(config, str(device))

if 'error' not in model_info:
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Param√®tres totaux", f"{model_info['total_params']:,}")
    with col2:
        st.metric("Param√®tres entra√Ænables", f"{model_info['trainable_params']:,}")
    with col3:
        st.metric("Device", model_info['device'])

# Section 3: Entra√Ænement
st.header("üöÄ 3. Entra√Ænement")

st.markdown("""
- **Dataset:** Mendeley Blood Cell Images
- **Optimiseur:** Adam
- **Loss function:** CrossEntropyLoss avec pond√©ration des classes
- **Data split:** 70% train / 15% validation / 15% test
""")

# Section 4: R√©-entra√Ænement du mod√®le
st.header("üîÑ 4. R√©-entra√Ænement du mod√®le")

st.markdown("""
Cliquez sur le bouton ci-dessous pour lancer l'entra√Ænement d'un nouveau mod√®le.
Le mod√®le sera automatiquement sauvegard√© dans le r√©pertoire `checkpoints`.
""")

# Initialize session state for training status
if 'training_in_progress' not in st.session_state:
    st.session_state.training_in_progress = False

col1, col2 = st.columns([1, 3])

with col1:
    if st.button("üöÄ Lancer l'entra√Ænement", type="primary", disabled=st.session_state.training_in_progress):
        st.session_state.training_in_progress = True
        st.rerun()

with col2:
    if st.session_state.training_in_progress:
        st.info("‚è≥ Entra√Ænement en cours... Veuillez patienter.")

# Training execution
if st.session_state.training_in_progress:
    with st.expander("üìä D√©tails de l'entra√Ænement", expanded=True):
        status_placeholder = st.empty()
        log_placeholder = st.empty()
        
        try:
            status_placeholder.info("üîÑ D√©marrage de l'entra√Ænement...")
            
            # Run training script using uv
            train_script = Path(yaml_loader.project_root) / "src" / "pipe" / "train_model.py"
            
            # Use subprocess to run the training
            process = subprocess.Popen(
                ["uv", "run", "python", "-m", "src.pipe.train_model"],
                cwd=yaml_loader.project_root,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True,
                bufsize=1
            )
            
            # Capture output in real-time
            output_lines = []
            for line in process.stdout:
                output_lines.append(line)
                log_placeholder.text_area("üìù Logs d'entra√Ænement", 
                                         value="".join(output_lines[-50:]),  # Show last 50 lines
                                         height=300)
            
            # Wait for process to complete
            process.wait()
            
            if process.returncode == 0:
                status_placeholder.success("‚úÖ Entra√Ænement termin√© avec succ√®s!")
                st.success(f"üéâ Le nouveau mod√®le a √©t√© sauvegard√© dans: `{config['paths']['models']['checkpoints']}`")
                st.info("üí° Rafra√Æchissez la page pour voir les nouvelles m√©triques.")
                
                # Reset training state
                time.sleep(2)
                st.session_state.training_in_progress = False
                st.rerun()
            else:
                status_placeholder.error(f"‚ùå Erreur lors de l'entra√Ænement (code: {process.returncode})")
                st.session_state.training_in_progress = False
                
        except Exception as e:
            status_placeholder.error(f"‚ùå Erreur: {str(e)}")
            st.session_state.training_in_progress = False

st.markdown("---")

# Section 5: √âvaluation
st.header("üéØ 5. √âvaluation")

# Load metrics by default from checkpoints directory
@st.cache_data
def load_evaluation_metrics():
    """Load evaluation metrics from the checkpoints directory."""
    metrics_path = Path(yaml_loader.project_root) / "models" / "checkpoints" / "metrics.json"
    
    if metrics_path.exists():
        try:
            with open(metrics_path, 'r') as f:
                return json.load(f), None
        except Exception as e:
            return None, f"Erreur lors du chargement des m√©triques: {e}"
    else:
        return None, "Aucun fichier de m√©triques trouv√©"

# Check for saved model
checkpoint_path = Path(yaml_loader.project_root) / "models" / "checkpoints" / "best_model.pth"
model_exists = checkpoint_path.exists()

if model_exists:
    import os
    from datetime import datetime
    
    # Get model file info
    model_size = os.path.getsize(checkpoint_path) / (1024 * 1024)  # Size in MB
    model_mtime = datetime.fromtimestamp(os.path.getmtime(checkpoint_path))
    
    st.info(f"üì¶ Mod√®le trouv√©: `best_model.pth` ({model_size:.1f} MB) - Derni√®re modification: {model_mtime.strftime('%Y-%m-%d %H:%M:%S')}")

# Load metrics automatically
metrics, error = load_evaluation_metrics()

if metrics is not None:
    st.success("‚úÖ M√©triques d'√©valuation charg√©es depuis le mod√®le entra√Æn√©")
    
    # Display main metrics in prominent cards
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("üéØ Test Accuracy", f"{metrics.get('accuracy', 0):.2%}")
    with col2:
        st.metric("üìà Best Val Accuracy", f"{metrics.get('best_val_acc', 0):.2%}")
    with col3:
        st.metric("üèãÔ∏è Final Train Accuracy", f"{metrics.get('final_train_acc', 0):.2%}")
    
    # Display confusion matrix if available
    if 'confusion_matrix' in metrics and 'class_names' in metrics:
        st.markdown("---")
        st.subheader("üìä Matrice de confusion")
        
        confusion_mat = np.array(metrics['confusion_matrix'])
        class_names_list = metrics['class_names']
        
        # Create annotated heatmap using plotly
        fig = ff.create_annotated_heatmap(
            z=confusion_mat,
            x=class_names_list,
            y=class_names_list,
            colorscale='Blues',
            showscale=True,
            annotation_text=confusion_mat.astype(str)
        )
        
        # Update layout
        fig.update_layout(
            title='Matrice de confusion (Test Set)',
            xaxis_title='Pr√©dictions',
            yaxis_title='Vraies √©tiquettes',
            height=600,
            width=800,
            xaxis={'side': 'bottom'},
            yaxis={'autorange': 'reversed'}
        )
        
        # Update font size for annotations
        for annotation in fig.layout.annotations:
            annotation.font.size = 10
        
        st.plotly_chart(fig, use_container_width=True)
        
        # Display per-class accuracy
        st.markdown("### üìà Pr√©cision par classe")
        
        # Calculate per-class accuracy
        per_class_acc = []
        for i, class_name in enumerate(class_names_list):
            total = confusion_mat[i].sum()
            correct = confusion_mat[i, i]
            accuracy = (correct / total * 100) if total > 0 else 0
            per_class_acc.append({
                'Classe': class_name,
                'Correct': int(correct),
                'Total': int(total),
                'Pr√©cision': f"{accuracy:.1f}%"
            })
        
        # Display as table
        df_acc = pd.DataFrame(per_class_acc)
        st.dataframe(df_acc, use_container_width=True, hide_index=True)
    
    # Additional metrics details
    with st.expander("üìä D√©tails complets des m√©triques", expanded=False):
        # Display metrics without confusion matrix (too large for JSON display)
        display_metrics = {k: v for k, v in metrics.items() if k != 'confusion_matrix'}
        st.json(display_metrics)
        
        # Display training loss if available
        if 'final_train_loss' in metrics:
            st.write(f"**Final Training Loss:** {metrics['final_train_loss']:.4f}")
        
        # Display class names
        if 'class_names' in metrics:
            st.write("**Classes d√©tect√©es:**")
            cols = st.columns(4)
            for i, class_name in enumerate(metrics['class_names']):
                with cols[i % 4]:
                    st.write(f"‚Ä¢ {class_name}")
elif model_exists:
    st.warning(f"‚ö†Ô∏è {error}")
    st.info("üí° Le mod√®le existe mais les m√©triques n'ont pas √©t√© sauvegard√©es. R√©-entra√Ænez le mod√®le pour g√©n√©rer les m√©triques.")
else:
    st.warning(f"‚ö†Ô∏è {error}")
    st.info("üí° Entra√Ænez d'abord le mod√®le en cliquant sur le bouton 'üöÄ Lancer l'entra√Ænement' ci-dessus.")
    st.markdown("""
    **Apr√®s entra√Ænement, cette section affichera:**
    - Accuracy sur le test set
    - Meilleure accuracy de validation
    - Accuracy finale d'entra√Ænement
    - Loss finale d'entra√Ænement
    """)

st.markdown("---")
st.caption("üõ†Ô∏è Cette page utilise les services backend: ModelFactory, DataTransformService, YamlLoader")